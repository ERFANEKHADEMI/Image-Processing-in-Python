{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges\n",
    "\n",
    "In this exercise you will identify the shapes in a grapefruit image by detecting the edges, using the Canny algorithm.\n",
    "\n",
    "Grapefruits\n",
    "Image preloaded as grapefruit.\n",
    "\n",
    "The color module has already been preloaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the canny edge detector \n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruit = color.rgb2grey(grapefruit)\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruit)\n",
    "\n",
    "# Show resulting image\n",
    "show_image(canny_edges, \"Edges with Canny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less edgy\n",
    "\n",
    "Let's now try to spot just the outer shape of the grapefruits, the circles. You can do this by applying a more intense Gaussian filter to first make the image smoother. This can be achieved by specifying a bigger sigma in the canny function.\n",
    "\n",
    "In this exercise, you'll experiment with sigma values of the canny() function.\n",
    "Grapefruits\n",
    "Image preloaded as grapefruit.\n",
    "\n",
    "The show_image has already been preloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply canny edge detector with a sigma of 1.8\n",
    "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
    "\n",
    "# Apply canny edge detector with a sigma of 2.2\n",
    "edges_2_2 = canny(grapefruit, sigma=2.2)\n",
    "\n",
    "# Show resulting images\n",
    "show_image(edges_1_8, \"Sigma of 1.8\")\n",
    "show_image(edges_2_2, \"Sigma of 2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perspective\n",
    "\n",
    "In this exercise, you will detect the corners of a building using the Harris corner detector. The threshold_rel parameter will specify the minimum intensity of peaks.\n",
    "\n",
    "Building from a bottom perspective\n",
    "Image preloaded as building_image.\n",
    "\n",
    "The functions show_image() and show_image_with_corners() have already been preloaded for you. As well as the color module for converting images to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the corner detector related functions and module\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "# Convert image from RGB-3 to grayscale\n",
    "building_image_gray = color.rgb2grey(building_image)\n",
    "\n",
    "# Apply the detector  to measure the possible corners\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Find the peaks of the corners using the Harris detector\n",
    "coords = corner_peaks(measure_image, min_distance=20, threshold_rel=0.02)\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image(building_image, \"Original\")\n",
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less corners\n",
    "\n",
    "In this exercise, you will test what happens when you set the minimum distance between corner peaks to be a higher number. Remember you do this with the min_distance attribute parameter of the corner_peaks() function. The threshold_rel parameter will specify the minimum intensity of peaks.\n",
    "\n",
    "Building from a bottom perspective\n",
    "Image preloaded as building_image.\n",
    "\n",
    "The functions show_image(), show_image_with_corners() and required packages have already been preloaded for you. As well as all the previous code for finding the corners. The Harris measure response image obtained with corner_harris() is preloaded as measure_image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peaks with a min distance of 10 pixels\n",
    "coords_w_min_10 = corner_peaks(measure_image, min_distance=10, threshold_rel=0.02)\n",
    "print(\"With a min_distance set to 10, we detect a total\", len(coords_w_min_10), \"corners in the image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is someone there?\n",
    "\n",
    "In this exercise, you will check whether or not there is a person present in an image taken at night.\n",
    "\n",
    "LAndscape of starry night with a young man in the left bottom corner\n",
    "Image preloaded as night_image.\n",
    "\n",
    "The Cascade of classifiers class from feature module has been already imported. The same is true for the show_detected_face() function, that is used to display the face marked in the image and crop so it can be shown separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img = night_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10,10),\n",
    "                                       max_size=(200,200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple faces\n",
    "\n",
    "In this exercise, you will detect multiple faces in an image and show them individually. Think of this as a way to create a dataset of your own friends' faces!\n",
    "\n",
    "A group of 7 friends\n",
    "Image preloaded as friends_image.\n",
    "\n",
    "The Cascade of classifiers class from feature module has already been imported, as well as the show_detected_face() function which is used to display the face marked in the image and crop it so it can be shown separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with scale factor to 1.2 and step ratio to 1\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "# Show the detected faces\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation and face detection\n",
    "\n",
    "Previously, you learned how to make processes more computationally efficient with unsupervised superpixel segmentation. In this exercise, you'll do just that!\n",
    "\n",
    "Using the slic() function for segmentation, pre-process the image before passing it to the face detector.\n",
    "Young woman selfie\n",
    "Image preloaded as profile_image.\n",
    "\n",
    "The Cascade class, the slic() function from segmentation module, and the show_detected_face() function for visualization have already been imported. The detector is already initialized and ready to use as detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the segmentation with default 100 regions\n",
    "segments = slic(profile_image, 100)\n",
    "\n",
    "# Obtain segmented image using label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg')\n",
    "\n",
    "# Detect the faces with multi scale method\n",
    "detected = detector.detect_multi_scale(img=segmented_image, \n",
    "                                       scale_factor=1.2, \n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10), max_size=(1000, 1000))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(segmented_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Privacy protection\n",
    "\n",
    "Let's look at a real-world application of what you have learned in the course.\n",
    "\n",
    "In this exercise, you will detect human faces in the image and for the sake of privacy, you will anonymize data by blurring people's faces in the image automatically.\n",
    "\n",
    "Group band walking\n",
    "Image preloaded as group_image.\n",
    "\n",
    "You can use the gaussian filter for the blurriness.\n",
    "\n",
    "The face detector is ready to use as detector and all packages needed have been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(img=group_image, \n",
    "                                       scale_factor=1.2, step_ratio=1, \n",
    "                                       min_size=(10,10), max_size=(100, 100))\n",
    "# For each detected face\n",
    "for d in detected:  \n",
    "    # Obtain the face rectangle from detected coordinates\n",
    "    face = getFaceRectangle(d)\n",
    "    \n",
    "    # Apply gaussian filter to extracted face\n",
    "    blurred_face = gaussian(face, multichannel=True, sigma = 8)\n",
    "    \n",
    "    # Merge this blurry face to our final image and show it\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face) \n",
    "show_image(resulting_image, \"Blurred faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help Sally restore her graduation photo\n",
    "\n",
    "You are going to combine all the knowledge you acquired throughout the course to complete a final challenge: reconstructing a very damaged photo.\n",
    "\n",
    "Help Sally restore her favorite portrait which was damaged by noise, distortion, and missing information due to a breach in her laptop.\n",
    "Sally damaged picture\n",
    "Sally's damaged portrait is already loaded as damaged_image.\n",
    "\n",
    "You will be fixing the problems of this image by:\n",
    "\n",
    "    Rotating it to be uprightusing rotate()\n",
    "    Applying noise reduction with denoise_tv_chambolle()\n",
    "    Reconstructing the damaged parts with inpaint_biharmonic() from the inpaint module.\n",
    "\n",
    "show_image() is already preloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "# Transform the image so it's not rotated\n",
    "upright_img = transform.rotate(damaged_image, 20)\n",
    "\n",
    "# Remove noise from the image, using the chambolle method\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "# Reconstruct the image missing parts\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "show_image(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
